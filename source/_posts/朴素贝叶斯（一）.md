---
title: 朴素贝叶斯（一）
tags: ['朴素贝叶斯', '机器学习']
categories: ['机器学习']
copyright: true
---
朴素贝叶斯（Naive Bayes）是一种简单的分类算法，它的经典应用案例为人所熟知：文本分类（如垃圾邮件过滤）。

#####  总结

1、朴素贝叶斯有个前提的假设：每个条件（属性）互相之间是独立的。

2、最初公式的分母是一个常数，忽略不计。

3、在做词分类时，考虑到词很多需要做大量的乘法会影响效率，再者小数的乘法会越乘越小导致数据很小丢失数据，因此对最终的公式做ln处理，不影响单调性，把乘法转换
成加法。

4、为了防止在计算时出现概率为0的情况，做一些平滑处理。  
（1）先验概率，分子加α，分母加kα k是类别总数（感觉不用平滑，分子为某个类别样本，而且有些地方的讲解没有用平滑）  
（2）每个条件的概率，分子加α，分母加nα n是特征维度  
当α=1时，称作Laplace平滑，当0<α<1时，称作Lidstone平滑，α=0时不做平滑。

上面的四点会在下面的详细讲解点出。

#####  公式及其推导

最初公式：

![](http://wiki.corp.qunar.com/confluence/download/thumbnails/191162695/image2
018-2-28_11-47-25.png?version=1&modificationDate=1519789645000&api=v2)

给定训练数据集  (  X  ,  Y  )  ，其中每个样本x都包括n维特征，即  x  =  (  x  1  ,  x  2  ,  x  3  ,
.  .  .  ,  x  n  )  ，类标记集合含有k种类别，即  y  =  (  y  1  ,  y  2  ,  .  .  .  ,  y
k  )  。

如果现在来了一个新样本  x，求其类别。

那么问题就转化为求解  P  (  y  1  |  x  )  ,  P  (  y  2  |  x  )  ,  .  .  .  ,  P  (
y  k  |  x  )  中最大的那个，即求后验概率最大的输出：  a  r  g  m  a  x  y  k  P  (  y  k  |  x
)

那  P  (  y  k  |  x  )  就通过贝叶斯定理求得：

![](http://wiki.corp.qunar.com/confluence/download/thumbnails/191162695/image2
018-2-28_11-50-49.png?version=1&modificationDate=1519789849000&api=v2)

分子中的  P  (  y  k  )  是先验概率，根据训练集样本数就可以简单地计算出来。

分母  P  (  x  )  可以根据全概率公式算，但是对于任何输入的数据都是一个常数，所以可以忽略不计。

  

而条件概率  P  (  x  |  y  k  )  =  P  (  x  1  ,  x  2  ,  .  .  .  ,  x  n  |  y
k  )  ，它的参数规模是指数数量级别的，假设第  i  维特征  x  i  可取值的个数有  S  i  个，类别取值个数为k个，那么参数个数为：
k  ∏  n  i  =  1  S  i

这显然不可行。针对这个问题，  ** 朴素贝叶斯算法对条件概率分布作出了独立性的假设 ** ，通俗地讲就是说假设各个维度的特征  x  1  ,  x  2
,  .  .  .  ,  x  n  互相独立  ，在这个假设的前提上，条件概率可以转化为：

![](http://wiki.corp.qunar.com/confluence/download/attachments/191162695/image
2018-2-28_11-52-52.png?version=1&modificationDate=1519789972000&api=v2)

公式最终转化成：

![](http://wiki.corp.qunar.com/confluence/download/thumbnails/191162695/image2
018-2-28_11-53-25.png?version=1&modificationDate=1519790006000&api=v2)

  

#####  平滑处理：

_ ** 某些属性在某些类别上不存在 ** _ ，因此会导致p(xi|yk)为0，因此需要一下平滑处理（ _ **
我一般不会对先验概率公式（下面第一个公式）做平滑，因为某个类别的样本数不会为0 ** _ ）：

![](http://wiki.corp.qunar.com/confluence/download/thumbnails/191162695/image2
018-2-28_11-57-26.png?version=1&modificationDate=1519790247000&api=v2)
N是样本总数，k是类别总数，  N  y  k  是类别为  y  k  的样本个数，  α  是平滑值。

![](http://wiki.corp.qunar.com/confluence/download/thumbnails/191162695/image2
018-2-28_11-57-47.png?version=1&modificationDate=1519790267000&api=v2) N  y  k
是类别为  y  k  的样本个数，n是特征的维数，  N  y  k  ,  x  i  是类别为  y  k  的样本中，第i维特征的值是  x  i
的样本个数，  α  是平滑值。

当  α  =  1  时，称作Laplace平滑，当  0  < α  < 1  时，称作Lidstone平滑，  α  =  0  时不做平滑。

  

#####  例1（来自下面的链接）：

![](http://wiki.corp.qunar.com/confluence/download/attachments/191162695/image
2018-2-28_12-2-27.png?version=1&modificationDate=1519790548000&api=v2)

![](http://wiki.corp.qunar.com/confluence/download/attachments/191162695/image
2018-2-28_12-2-59.png?version=1&modificationDate=1519790579000&api=v2)

![](http://wiki.corp.qunar.com/confluence/download/attachments/191162695/image
2018-2-28_12-3-10.png?version=1&modificationDate=1519790590000&api=v2)

由此可以判定y=-1。

  

参考： [ http://blog.csdn.net/u013007900/article/details/78049587
](http://blog.csdn.net/u013007900/article/details/78049587)

