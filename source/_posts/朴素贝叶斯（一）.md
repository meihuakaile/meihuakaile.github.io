---
title: '朴素贝叶斯（一）'
date: "2018/04/08"
tags: ['朴素贝叶斯', '机器学习']
categories: ['机器学习']
copyright: true
---
朴素贝叶斯（Naive Bayes）是一种简单的分类算法，它的经典应用案例为人所熟知：文本分类（如垃圾邮件过滤）。

#####  总结

1、朴素贝叶斯有个前提的假设：每个条件（属性）互相之间是独立的。
2、最初公式的分母是一个常数，忽略不计。
3、在做词分类时，考虑到词很多需要做大量的乘法会影响效率，再者小数的乘法会越乘越小导致数据很小丢失数据，因此对最终的公式做ln处理，不影响单调性，把乘法转换成加法。
4、为了防止在计算时出现概率为0的情况，做一些平滑处理。  
（1）先验概率，分子加α，分母加kα k是类别总数（感觉不用平滑，分子为某个类别样本数）  
（2）每个条件的概率，分子加α，分母加nα n是特征维度  
当α=1时，称作Laplace平滑;当0<α<1时，称作Lidstone平滑;α=0时不做平滑。

上面的四点会在下面的详细讲解点出。

#####  公式及其推导

最初公式：

![](34.png)

给定训练数据集(X, Y)，其中每个样本x都包括n维特征，即x=(x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>,. . . ,  x<sub>n</sub>)，类标记集合含有k种类别，即y=(y<sub>1</sub>, y<sub>2</sub>,. . . , y<sub>k</sub>)。
如果现在来了一个新样本x，求其类别。
那么问题就转化为求解P(y<sub>1</sub>|x),P(y<sub>2</sub>|x ) , . . . , P(y<sub>k</sub>|x)中最大的那个，即求后验概率最大的输出：argmaxykP(y<sub>k</sub>|x)

那P(y<sub>k</sub>|x)就通过贝叶斯定理求得：
![](35.png)

分子中的P(y<sub>k</sub>) 是先验概率，根据训练集样本数就可以简单地计算出来。
分母P(x)可以根据全概率公式算，但是对于任何输入的数据都是一个常数，所以可以忽略不计。
而条件概率P(x|y<sub>k</sub>)=P(x<sub>1</sub>,x<sub>2</sub>, . . . , x<sub>n</sub>|y<sub>k</sub>)，它的参数规模是指数数量级别的，假设第i维特征x<sub>i</sub>可取值的个数有S<sub>i</sub>个，类别取值个数为k个，那么参数个数为：
k∏n<sub>i</sub>=1  S<sub>i</sub>
这显然不可行。针对这个问题，  ** 朴素贝叶斯算法对条件概率分布作出了独立性的假设 ** ，通俗地讲就是说假设各个维度的特征x<sub>1</sub>, x<sub>2</sub>,  .  .  .  ,  x<sub>n</sub>互相独立  ，在这个假设的前提上，条件概率可以转化为：

![](36.png)

公式最终转化成：

![](37.png)

  

#####  平滑处理

_ ** 某些属性在某些类别上不存在 ** _ ，因此会导致p(x<sub>i</sub>|y<sub>k</sub>)为0，因此需要一下平滑处理（ _ **我一般不会对先验概率公式（下面第一个公式）做平滑，因为某个类别的样本数一般不会为0 ** _ ）：
N是样本总数，k是类别总数，N<sub>y<sub>k</sub></sub>是类别为y<sub>k</sub>的样本个数，α是平滑值。
![](38.png)
N<sub>y<sub>k</sub></sub>是类别为y<sub>k</sub>的样本个数，n是特征的维数，N<sub>y<sub>k</sub>,x<sub>i</sub></sub>是类别为y<sub>k</sub>的样本中，特征的值是x<sub>i</sub>的样本个数，α是平滑值。
![](39.png) 
当α=1时，称作Laplace平滑，当0<α < 1 时，称作Lidstone平滑， α=0时不做平滑。

#####  例
（来自下面的链接）：
![](40.png)
![](41.png)
![](42.png)
由此可以判定y=-1。

更详细可参考 ： [ 朴素贝叶斯（二）实现NBCorpus分类（附代码和数据） ](/2018/04/08/朴素贝叶斯（二）实现NBCorpus分类（附代码和数据）)
参考： [ http://blog.csdn.net/u013007900/article/details/78049587
](http://blog.csdn.net/u013007900/article/details/78049587)

