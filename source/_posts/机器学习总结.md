---
title: '机器学习'
date: "2018/10/19"
tags: [机器学习]
categories: ['机器学习']
copyright: true
---
1、线性回归和逻辑回归在计算之前先对数据处理，把无关、想似的属性去除，效果会好。

2、朴素贝叶斯有个强假设，假设每个属性都是独立的，不相关的。

3、KNN算法当输入数据维度很高时（也可以理解成属性很多），效果会变差。主要是因为输入变量的数量对于算法性能有着很大的负面影响。

4、支持向量机可能是最受欢迎、讨论最为广泛的机器学习算法之一。

5、如果用方差较高的算法（如决策树）能够获得较好的结果，那么通过bagging算法通常可以获得更好的结果。

6、通常，AdaBoost算法与决策树一起工作。第一个决策树创建后，决策树在每个训练实例上的性能，都被用来衡量下一个决策树针对该实例所应分配的关注程度。难以预测的训练数据被赋予更大的权重，而容易预测的数据则被赋予更小的权重。模型依次被创建，每次更新训练实例的权重，都会影响到序列中下一个决策树学习性能。所有决策树完成后，即可对新输入的数据进行预测，而每个决策树的性能将由它在训练数据上的准确度所决定。